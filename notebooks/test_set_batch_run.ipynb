{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llm_political_analysis.modules.analyze import bulk_analyze_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/plaintext/1 Test - POR1999 Soc Dem.txt',\n",
       " '../data/plaintext/1 Test - BUL 2014 Attack.txt',\n",
       " '../data/plaintext/1 Test - NOR 1989 Conservative txt.txt',\n",
       " '../data/plaintext/1 Test - FR 2002 FN txt.txt',\n",
       " '../data/plaintext/1 Test - SLO 2006 Xtian Dem Movement.txt',\n",
       " '../data/plaintext/1 Test - CRO 2003 Democratic Union.txt',\n",
       " '../data/plaintext/1 Test - POL 2019 Civic Coalition.txt',\n",
       " '../data/plaintext/1 Test - SWE 2010 Moderate.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist = os.listdir('../data/plaintext/')\n",
    "test_files = ['../data/plaintext/'+file for file in filelist if 'Test' in file]\n",
    "test_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['gpt-4o', 'gemini-1.5-pro-001', 'claude-3-5-sonnet-20240620']\n",
    "issue_list = ['european_union', 'taxation', 'lifestyle', 'immigration', 'environment', 'decentralization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file:  ../data/plaintext/1 Test - POR1999 Soc Dem.txt\n",
      "Summarized so far: 2 out of 2 chunks\n",
      "Combining summaries into one final summary\n",
      "Final summary length: 5384 characters \n",
      "\n",
      "-- Analyzing issue:  european_union\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  taxation\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  lifestyle\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  immigration\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  environment\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  decentralization\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "Analyzing file:  ../data/plaintext/1 Test - BUL 2014 Attack.txt\n",
      "Summarized so far: 1 out of 1 chunks\n",
      "Final summary length: 2994 characters \n",
      "\n",
      "-- Analyzing issue:  european_union\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  taxation\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  lifestyle\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  immigration\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  environment\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  decentralization\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "Analyzing file:  ../data/plaintext/1 Test - NOR 1989 Conservative txt.txt\n",
      "Waiting for 50 seconds to avoid token limit\n",
      "Waiting for 51 seconds to avoid token limit\n",
      "Waiting for 49 seconds to avoid token limit\n",
      "Summarized so far: 4 out of 4 chunks\n",
      "Combining summaries into one final summary\n",
      "Final summary length: 4576 characters \n",
      "\n",
      "-- Analyzing issue:  european_union\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  taxation\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  lifestyle\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  immigration\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  environment\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  decentralization\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "Analyzing file:  ../data/plaintext/1 Test - FR 2002 FN txt.txt\n",
      "Waiting for 49 seconds to avoid token limit\n",
      "Waiting for 46 seconds to avoid token limit\n",
      "Summarized so far: 3 out of 3 chunks\n",
      "Combining summaries into one final summary\n",
      "Final summary length: 5154 characters \n",
      "\n",
      "-- Analyzing issue:  european_union\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  taxation\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  lifestyle\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  immigration\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  environment\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  decentralization\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "Analyzing file:  ../data/plaintext/1 Test - SLO 2006 Xtian Dem Movement.txt\n",
      "Summarized so far: 1 out of 1 chunks\n",
      "Final summary length: 4120 characters \n",
      "\n",
      "-- Analyzing issue:  european_union\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  taxation\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  lifestyle\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  immigration\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  environment\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  decentralization\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "Analyzing file:  ../data/plaintext/1 Test - CRO 2003 Democratic Union.txt\n",
      "Waiting for 50 seconds to avoid token limit\n",
      "Summarized so far: 2 out of 2 chunks\n",
      "Combining summaries into one final summary\n",
      "Final summary length: 5810 characters \n",
      "\n",
      "-- Analyzing issue:  european_union\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  taxation\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  lifestyle\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  immigration\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  environment\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  decentralization\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "Analyzing file:  ../data/plaintext/1 Test - POL 2019 Civic Coalition.txt\n",
      "Waiting for 51 seconds to avoid token limit\n",
      "Summarized so far: 2 out of 2 chunks\n",
      "Combining summaries into one final summary\n",
      "Final summary length: 4587 characters \n",
      "\n",
      "-- Analyzing issue:  european_union\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  taxation\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  lifestyle\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  immigration\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  environment\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  decentralization\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "Analyzing file:  ../data/plaintext/1 Test - SWE 2010 Moderate.txt\n",
      "Waiting for 49 seconds to avoid token limit\n",
      "Summarized so far: 2 out of 2 chunks\n",
      "Combining summaries into one final summary\n",
      "Final summary length: 5470 characters \n",
      "\n",
      "-- Analyzing issue:  european_union\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  taxation\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  lifestyle\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  immigration\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  environment\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n",
      "-- Analyzing issue:  decentralization\n",
      "---- Analyzing with model:  gpt-4o\n",
      "---- Analyzing with model:  gemini-1.5-pro-001\n",
      "---- Analyzing with model:  claude-3-5-sonnet-20240620\n"
     ]
    }
   ],
   "source": [
    "# Bump up concurrency to 9 for faster processing with a Tier 2 OpenAI key, keep at 3 for Tier 1\n",
    "results = bulk_analyze_text(test_files, model_list, issue_list, results_file='../data/results/test_set_results.xlsx', concurrency=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>issue</th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>error_message</th>\n",
       "      <th>prompt</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/plaintext/1 Test - POR1999 Soc Dem.txt</td>\n",
       "      <td>european_union</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are an expert social scien...</td>\n",
       "      <td>2024-06-30 07:38:53.135728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/plaintext/1 Test - POR1999 Soc Dem.txt</td>\n",
       "      <td>european_union</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are an expert social scien...</td>\n",
       "      <td>2024-06-30 07:38:53.135728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/plaintext/1 Test - POR1999 Soc Dem.txt</td>\n",
       "      <td>european_union</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are an expert social scien...</td>\n",
       "      <td>2024-06-30 07:38:53.135728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/plaintext/1 Test - POR1999 Soc Dem.txt</td>\n",
       "      <td>european_union</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are highly intelligent.  T...</td>\n",
       "      <td>2024-06-30 07:38:53.135728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/plaintext/1 Test - POR1999 Soc Dem.txt</td>\n",
       "      <td>european_union</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are highly intelligent.  T...</td>\n",
       "      <td>2024-06-30 07:38:53.135728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>../data/plaintext/1 Test - SWE 2010 Moderate.txt</td>\n",
       "      <td>decentralization</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are highly intelligent.  T...</td>\n",
       "      <td>2024-06-30 07:58:27.080289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>../data/plaintext/1 Test - SWE 2010 Moderate.txt</td>\n",
       "      <td>decentralization</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are highly intelligent.  I...</td>\n",
       "      <td>2024-06-30 07:58:27.080289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>../data/plaintext/1 Test - SWE 2010 Moderate.txt</td>\n",
       "      <td>decentralization</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are a professor of economi...</td>\n",
       "      <td>2024-06-30 07:58:27.080289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>../data/plaintext/1 Test - SWE 2010 Moderate.txt</td>\n",
       "      <td>decentralization</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are a professor of economi...</td>\n",
       "      <td>2024-06-30 07:58:27.080289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>../data/plaintext/1 Test - SWE 2010 Moderate.txt</td>\n",
       "      <td>decentralization</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>[content='\\n    You are a professor of economi...</td>\n",
       "      <td>2024-06-30 07:58:27.080289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file             issue  \\\n",
       "0       ../data/plaintext/1 Test - POR1999 Soc Dem.txt    european_union   \n",
       "1       ../data/plaintext/1 Test - POR1999 Soc Dem.txt    european_union   \n",
       "2       ../data/plaintext/1 Test - POR1999 Soc Dem.txt    european_union   \n",
       "3       ../data/plaintext/1 Test - POR1999 Soc Dem.txt    european_union   \n",
       "4       ../data/plaintext/1 Test - POR1999 Soc Dem.txt    european_union   \n",
       "...                                                ...               ...   \n",
       "1291  ../data/plaintext/1 Test - SWE 2010 Moderate.txt  decentralization   \n",
       "1292  ../data/plaintext/1 Test - SWE 2010 Moderate.txt  decentralization   \n",
       "1293  ../data/plaintext/1 Test - SWE 2010 Moderate.txt  decentralization   \n",
       "1294  ../data/plaintext/1 Test - SWE 2010 Moderate.txt  decentralization   \n",
       "1295  ../data/plaintext/1 Test - SWE 2010 Moderate.txt  decentralization   \n",
       "\n",
       "                           model score error_message  \\\n",
       "0                         gpt-4o     6          None   \n",
       "1                         gpt-4o     6          None   \n",
       "2                         gpt-4o     6          None   \n",
       "3                         gpt-4o     6          None   \n",
       "4                         gpt-4o     6          None   \n",
       "...                          ...   ...           ...   \n",
       "1291  claude-3-5-sonnet-20240620     3          None   \n",
       "1292  claude-3-5-sonnet-20240620     3          None   \n",
       "1293  claude-3-5-sonnet-20240620     3          None   \n",
       "1294  claude-3-5-sonnet-20240620     3          None   \n",
       "1295  claude-3-5-sonnet-20240620     3          None   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0     [content='\\n    You are an expert social scien...   \n",
       "1     [content='\\n    You are an expert social scien...   \n",
       "2     [content='\\n    You are an expert social scien...   \n",
       "3     [content='\\n    You are highly intelligent.  T...   \n",
       "4     [content='\\n    You are highly intelligent.  T...   \n",
       "...                                                 ...   \n",
       "1291  [content='\\n    You are highly intelligent.  T...   \n",
       "1292  [content='\\n    You are highly intelligent.  I...   \n",
       "1293  [content='\\n    You are a professor of economi...   \n",
       "1294  [content='\\n    You are a professor of economi...   \n",
       "1295  [content='\\n    You are a professor of economi...   \n",
       "\n",
       "                     created_at  \n",
       "0    2024-06-30 07:38:53.135728  \n",
       "1    2024-06-30 07:38:53.135728  \n",
       "2    2024-06-30 07:38:53.135728  \n",
       "3    2024-06-30 07:38:53.135728  \n",
       "4    2024-06-30 07:38:53.135728  \n",
       "...                         ...  \n",
       "1291 2024-06-30 07:58:27.080289  \n",
       "1292 2024-06-30 07:58:27.080289  \n",
       "1293 2024-06-30 07:58:27.080289  \n",
       "1294 2024-06-30 07:58:27.080289  \n",
       "1295 2024-06-30 07:58:27.080289  \n",
       "\n",
       "[1296 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_poli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
